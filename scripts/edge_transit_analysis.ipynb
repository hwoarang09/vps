{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Transit Log Analysis\n",
    "\n",
    "Fab별 반송 효율 분석을 위한 노트북\n",
    "\n",
    "## 분석 가능 항목\n",
    "- Throughput (시간당 처리량)\n",
    "- Transit Time (Edge 통과 시간)\n",
    "- Vehicle 활용률\n",
    "- Edge별 혼잡도\n",
    "- Fab간 비교 분석\n",
    "- 여러 실험 결과 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "print('Setup complete!')\n",
    "print(f'Polars version: {pl.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 로그 파일 경로 설정\n",
    "LOG_DIR = Path('/content/drive/MyDrive/vps_logs')  # 필요시 수정\n",
    "print(f'Log directory: {LOG_DIR}')\n",
    "\n",
    "# 파일 목록 확인\n",
    "if LOG_DIR.exists():\n",
    "    log_files = list(LOG_DIR.glob('*.bin'))\n",
    "    print(f'Found {len(log_files)} log files:')\n",
    "    for f in log_files:\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f'  - {f.name} ({size_kb:.1f} KB)')\n",
    "else:\n",
    "    print(f'Directory not found: {LOG_DIR}')\n",
    "    print('Create the directory and upload your .bin files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Format\n",
    "RECORD_SIZE = 28\n",
    "RECORD_FORMAT = '<I BB H I I I f B 3x'  # little-endian\n",
    "\n",
    "EDGE_TYPES = {\n",
    "    0: 'LINEAR',\n",
    "    1: 'CURVE_90',\n",
    "    2: 'CURVE_180',\n",
    "    3: 'CURVE_CSC',\n",
    "    4: 'S_CURVE',\n",
    "    5: 'LEFT_CURVE',\n",
    "    6: 'RIGHT_CURVE',\n",
    "}\n",
    "\n",
    "# Edge Type별 기대 속도 (m/s) - 직선이 더 빠름\n",
    "EXPECTED_SPEEDS = {\n",
    "    'LINEAR': 3.0,      # 직선: 3.0 m/s\n",
    "    'CURVE_90': 2.2,    # 곡선: 더 느림\n",
    "    'CURVE_180': 2.0,\n",
    "    'CURVE_CSC': 2.2,\n",
    "    'S_CURVE': 2.3,\n",
    "    'LEFT_CURVE': 2.2,\n",
    "    'RIGHT_CURVE': 2.2,\n",
    "}\n",
    "\n",
    "def format_edge_id(edge_id):\n",
    "    \"\"\"Edge ID를 E0001 형식으로 포맷팅\"\"\"\n",
    "    return f\"E{edge_id+1:04d}\"\n",
    "\n",
    "def parse_log_file(filepath):\n",
    "    \"\"\"바이너리 로그 파일을 Polars DataFrame으로 변환\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    for i in range(0, len(data), RECORD_SIZE):\n",
    "        chunk = data[i:i+RECORD_SIZE]\n",
    "        if len(chunk) < RECORD_SIZE:\n",
    "            break\n",
    "        \n",
    "        r = struct.unpack(RECORD_FORMAT, chunk)\n",
    "        records.append({\n",
    "            'timestamp': r[0],\n",
    "            'worker_id': r[1],\n",
    "            'fab_id': r[2],\n",
    "            'edge_id': r[3],\n",
    "            'veh_id': r[4],\n",
    "            'enter_time': r[5],\n",
    "            'exit_time': r[6],\n",
    "            'edge_length': r[7],\n",
    "            'edge_type': r[8],\n",
    "        })\n",
    "    \n",
    "    # Polars DataFrame 생성\n",
    "    df = pl.DataFrame(records)\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        # 계산 컬럼 추가\n",
    "        df = df.with_columns([\n",
    "            (pl.col('exit_time') - pl.col('enter_time')).alias('transit_time'),\n",
    "            pl.col('edge_type').replace_strict(EDGE_TYPES, default='UNKNOWN').alias('edge_type_name'),\n",
    "            (pl.col('timestamp') / 1000.0).alias('timestamp_sec'),\n",
    "            (pl.col('enter_time') / 1000.0).alias('enter_time_sec'),\n",
    "            (pl.col('exit_time') / 1000.0).alias('exit_time_sec'),\n",
    "            pl.format('E{}', (pl.col('edge_id') + 1).cast(pl.Utf8).str.zfill(4)).alias('edge_id_fmt'),\n",
    "        ])\n",
    "        \n",
    "        # Speed 계산 (0으로 나누기 방지)\n",
    "        df = df.with_columns([\n",
    "            pl.when(pl.col('transit_time') > 0)\n",
    "              .then(pl.col('edge_length') / (pl.col('transit_time') / 1000.0))\n",
    "              .otherwise(None)\n",
    "              .alias('speed')\n",
    "        ])\n",
    "        \n",
    "        # Edge ID 포맷 추가\n",
    "        df = df.with_columns([\n",
    "            (pl.col('edge_id') + 1).cast(pl.Utf8).str.zfill(4).str.concat('E').alias('edge_id_fmt')\n",
    "        ])\n",
    "        # 재정렬 (E0001, E0002, ...)\n",
    "        df = df.with_columns([\n",
    "            pl.format('E{}', (pl.col('edge_id') + 1).cast(pl.Utf8).str.zfill(4)).alias('edge_id_fmt')\n",
    "        ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('Parser ready!')\n",
    "print('Edge type별 기대 속도:', EXPECTED_SPEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 파일 로드 (파일명 수정 필요)\n",
    "# LOG_FILE = LOG_DIR / 'edge_transit_sim_xxx.bin'\n",
    "LOG_FILE = log_files[0] if log_files else None  # 첫 번째 파일 사용\n",
    "\n",
    "if LOG_FILE:\n",
    "    df = parse_log_file(LOG_FILE)\n",
    "    print(f'Loaded: {LOG_FILE.name}')\n",
    "    print(f'Total records: {len(df):,}')\n",
    "    print(f'\\nDataFrame shape: {df.shape}')\n",
    "    print(f'\\nColumns: {df.columns}')\n",
    "    print(f'\\nSchema:\\n{df.schema}')\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(df, name='Dataset'):\n",
    "    \"\"\"데이터셋 요약 출력\"\"\"\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'{name} Summary')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    print(f'\\nTotal Records: {len(df):,}')\n",
    "    print(f'Unique Vehicles: {df[\"veh_id\"].n_unique()}')\n",
    "    print(f'Unique Edges: {df[\"edge_id\"].n_unique()}')\n",
    "    print(f'Unique Fabs: {df[\"fab_id\"].n_unique()}')\n",
    "    print(f'Unique Workers: {df[\"worker_id\"].n_unique()}')\n",
    "    \n",
    "    duration = (df['timestamp'].max() - df['timestamp'].min()) / 1000\n",
    "    print(f'\\nSimulation Duration: {duration:.1f} seconds')\n",
    "    print(f'Throughput: {len(df) / duration:.1f} transits/sec')\n",
    "    \n",
    "    transit_stats = df.select([\n",
    "        pl.col('transit_time').mean().alias('mean'),\n",
    "        pl.col('transit_time').median().alias('median'),\n",
    "        pl.col('transit_time').std().alias('std'),\n",
    "        pl.col('transit_time').min().alias('min'),\n",
    "        pl.col('transit_time').max().alias('max'),\n",
    "    ]).row(0)\n",
    "    \n",
    "    print(f'\\nTransit Time (ms):')\n",
    "    print(f'  Mean: {transit_stats[0]:.1f}')\n",
    "    print(f'  Median: {transit_stats[1]:.1f}')\n",
    "    print(f'  Std: {transit_stats[2]:.1f}')\n",
    "    print(f'  Min: {transit_stats[3]}')\n",
    "    print(f'  Max: {transit_stats[4]}')\n",
    "    \n",
    "    speed_stats = df.select([\n",
    "        pl.col('speed').drop_nulls().mean().alias('mean'),\n",
    "        pl.col('speed').drop_nulls().median().alias('median'),\n",
    "    ]).row(0)\n",
    "    \n",
    "    print(f'\\nSpeed (m/s):')\n",
    "    print(f'  Mean: {speed_stats[0]:.2f}')\n",
    "    print(f'  Median: {speed_stats[1]:.2f}')\n",
    "\n",
    "print_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# Fab별 통계\nfab_stats = df.group_by('fab_id').agg([\n    pl.col('veh_id').n_unique().alias('unique_vehicles'),\n    pl.col('edge_id').n_unique().alias('unique_edges'),\n    pl.len().alias('transit_count'),\n    pl.col('timestamp').min().alias('timestamp_min'),\n    pl.col('timestamp').max().alias('timestamp_max'),\n    pl.col('transit_time').mean().alias('transit_mean'),\n    pl.col('transit_time').median().alias('transit_median'),\n    pl.col('transit_time').std().alias('transit_std'),\n    pl.col('speed').mean().alias('speed_mean'),\n]).with_columns([\n    ((pl.col('timestamp_max') - pl.col('timestamp_min')) / 1000).alias('duration_sec'),\n]).with_columns([\n    (pl.col('transit_count') / pl.col('duration_sec')).alias('throughput'),\n]).sort('fab_id')\n\nprint('\\nFab-level Statistics:')\nfab_stats\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Throughput Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\ndef plot_throughput_over_time(df, window_sec=1.0, by_fab=True):\n    \"\"\"시간에 따른 Throughput 시각화 (Plotly)\"\"\"\n    \n    # 전체 Throughput 계산\n    df_sorted = df.sort('timestamp')\n    min_time = df_sorted['timestamp_sec'].min()\n    \n    df_sorted = df_sorted.with_columns([\n        ((pl.col('timestamp_sec') - min_time) / window_sec).floor().cast(pl.Int64).alias('time_bin')\n    ])\n    \n    throughput = df_sorted.group_by('time_bin').agg([\n        pl.len().alias('count')\n    ]).sort('time_bin')\n    \n    throughput = throughput.with_columns([\n        (pl.col('time_bin') * window_sec).alias('time_sec'),\n        (pl.col('count') / window_sec).alias('throughput')\n    ])\n    \n    # Subplots 생성\n    if by_fab and df['fab_id'].n_unique() > 1:\n        fig = make_subplots(\n            rows=2, cols=1,\n            subplot_titles=('Overall Throughput', 'Throughput by Fab'),\n            vertical_spacing=0.12\n        )\n    else:\n        fig = make_subplots(rows=1, cols=1)\n    \n    # 전체 Throughput\n    mean_throughput = throughput['throughput'].mean()\n    \n    fig.add_trace(\n        go.Scatter(\n            x=throughput['time_sec'].to_list(),\n            y=throughput['throughput'].to_list(),\n            mode='lines',\n            name='Throughput',\n            fill='tozeroy',\n            line=dict(color='blue', width=1),\n        ),\n        row=1, col=1\n    )\n    \n    fig.add_hline(\n        y=mean_throughput,\n        line_dash='dash',\n        line_color='red',\n        annotation_text=f'Mean: {mean_throughput:.1f}',\n        row=1, col=1\n    )\n    \n    # Fab별 Throughput\n    if by_fab and df['fab_id'].n_unique() > 1:\n        for fab_id in sorted(df['fab_id'].unique().to_list()):\n            fab_df = df_sorted.filter(pl.col('fab_id') == fab_id)\n            fab_throughput = fab_df.group_by('time_bin').agg([\n                pl.len().alias('count')\n            ]).sort('time_bin').with_columns([\n                (pl.col('time_bin') * window_sec).alias('time_sec'),\n                (pl.col('count') / window_sec).alias('throughput')\n            ])\n            \n            fig.add_trace(\n                go.Scatter(\n                    x=fab_throughput['time_sec'].to_list(),\n                    y=fab_throughput['throughput'].to_list(),\n                    mode='lines',\n                    name=f'Fab {fab_id}',\n                    line=dict(width=1),\n                ),\n                row=2, col=1\n            )\n    \n    # Layout 설정\n    fig.update_xaxes(title_text='Time (seconds)', row=1, col=1)\n    fig.update_yaxes(title_text='Throughput (transits/sec)', row=1, col=1)\n    \n    if by_fab and df['fab_id'].n_unique() > 1:\n        fig.update_xaxes(title_text='Time (seconds)', row=2, col=1)\n        fig.update_yaxes(title_text='Throughput (transits/sec)', row=2, col=1)\n    \n    fig.update_layout(\n        height=800 if by_fab and df['fab_id'].n_unique() > 1 else 400,\n        showlegend=True,\n        title_text=f'Throughput Analysis (window={window_sec}s)'\n    )\n    \n    fig.show()\n\nplot_throughput_over_time(df, window_sec=1.0)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transit Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transit_time_distribution(df):\n",
    "    \"\"\"Transit Time 분포 시각화 (Plotly)\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Transit Time Distribution',\n",
    "            'Transit Time by Edge Type',\n",
    "            'Transit Time by Fab',\n",
    "            'Speed Distribution'\n",
    "        ),\n",
    "        specs=[[{'type': 'histogram'}, {'type': 'box'}],\n",
    "               [{'type': 'box'}, {'type': 'histogram'}]]\n",
    "    )\n",
    "    \n",
    "    # 1. 전체 분포 (히스토그램)\n",
    "    transit_times = df['transit_time'].to_list()\n",
    "    mean_transit = df['transit_time'].mean()\n",
    "    median_transit = df['transit_time'].median()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=transit_times,\n",
    "            nbinsx=50,\n",
    "            name='Transit Time',\n",
    "            marker_color='lightblue',\n",
    "            marker_line_color='black',\n",
    "            marker_line_width=0.5,\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=mean_transit,\n",
    "        line_dash='dash',\n",
    "        line_color='red',\n",
    "        annotation_text=f'Mean: {mean_transit:.1f}ms',\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=median_transit,\n",
    "        line_dash='dash',\n",
    "        line_color='green',\n",
    "        annotation_text=f'Median: {median_transit:.1f}ms',\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Edge Type별 분포\n",
    "    edge_types = df.select(pl.col('edge_type_name').drop_nulls().unique()).to_series().to_list()\n",
    "    for edge_type in edge_types:\n",
    "        transit_data = df.filter(pl.col('edge_type_name') == edge_type)['transit_time'].to_list()\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=transit_data,\n",
    "                name=edge_type,\n",
    "                boxmean='sd'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. Fab별 분포\n",
    "    if df['fab_id'].n_unique() > 1:\n",
    "        for fab_id in sorted(df['fab_id'].unique().to_list()):\n",
    "            transit_data = df.filter(pl.col('fab_id') == fab_id)['transit_time'].to_list()\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=transit_data,\n",
    "                    name=f'Fab {fab_id}',\n",
    "                    boxmean='sd'\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    else:\n",
    "        fig.add_annotation(\n",
    "            text='Single Fab',\n",
    "            xref='x3', yref='y3',\n",
    "            x=0.5, y=0.5,\n",
    "            showarrow=False,\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Speed 분포\n",
    "    valid_speeds = df.select(pl.col('speed').drop_nulls())['speed'].to_list()\n",
    "    mean_speed = df.select(pl.col('speed').drop_nulls().mean()).item()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=valid_speeds,\n",
    "            nbinsx=50,\n",
    "            name='Speed',\n",
    "            marker_color='lightcoral',\n",
    "            marker_line_color='black',\n",
    "            marker_line_width=0.5,\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=mean_speed,\n",
    "        line_dash='dash',\n",
    "        line_color='red',\n",
    "        annotation_text=f'Mean: {mean_speed:.2f}m/s',\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Layout 설정\n",
    "    fig.update_xaxes(title_text='Transit Time (ms)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Count', row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Edge Type', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Transit Time (ms)', row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Fab', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Transit Time (ms)', row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Speed (m/s)', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Count', row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        showlegend=True,\n",
    "        title_text='Transit Time Analysis'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_transit_time_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edge Congestion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\ndef analyze_edge_congestion(df, top_n=20):\n    \"\"\"Edge별 혼잡도 분석 - Edge Type별 기대 속도 반영\"\"\"\n    \n    edge_stats = df.group_by('edge_id').agg([\n        pl.len().alias('transit_count'),\n        pl.col('transit_time').mean().alias('transit_mean'),\n        pl.col('transit_time').median().alias('transit_median'),\n        pl.col('transit_time').std().alias('transit_std'),\n        pl.col('transit_time').max().alias('transit_max'),\n        pl.col('speed').mean().alias('speed_mean'),\n        pl.col('edge_length').first().alias('edge_length'),\n        pl.col('edge_type_name').first().alias('edge_type'),\n    ])\n    \n    # Edge ID 포맷 생성 (숫자 edge_id 기반)\n    edge_stats = edge_stats.with_columns([\n        pl.format('E{}', (pl.col('edge_id') + 1).cast(pl.Utf8).str.zfill(4)).alias('edge_id_fmt')\n    ])\n    \n    # Edge Type별 기대 속도 매핑 (when-then 체인 사용)\n    expected_speed_expr = pl.col('edge_type')\n    for type_name, speed in EXPECTED_SPEEDS.items():\n        if type_name == 'LINEAR':\n            expected_speed_expr = pl.when(pl.col('edge_type') == type_name).then(pl.lit(speed))\n        else:\n            expected_speed_expr = expected_speed_expr.when(pl.col('edge_type') == type_name).then(pl.lit(speed))\n    expected_speed_expr = expected_speed_expr.otherwise(pl.lit(3.0)).alias('expected_speed')\n    \n    edge_stats = edge_stats.with_columns([\n        expected_speed_expr\n    ]).with_columns([\n        (pl.col('edge_length') / pl.col('expected_speed') * 1000).alias('expected_time')\n    ]).with_columns([\n        (pl.col('transit_count').cast(pl.Float64) * (pl.col('transit_mean') / pl.col('expected_time'))).alias('congestion_score')\n    ])\n    \n    edge_stats_sorted = edge_stats.sort('congestion_score', descending=True)\n    \n    print(f'\\nTop {top_n} Congested Edges:')\n    print(edge_stats_sorted.head(top_n))\n    \n    # 시각화\n    fig = make_subplots(\n        rows=1, cols=2,\n        subplot_titles=('Edge Usage Distribution', f'Top {top_n} Congested Edges'),\n        column_widths=[0.4, 0.6]\n    )\n    \n    # 1. 통과 횟수 분포\n    transit_counts = edge_stats['transit_count'].to_list()\n    fig.add_trace(\n        go.Histogram(\n            x=transit_counts,\n            nbinsx=30,\n            marker_color='lightblue',\n            marker_line_color='black',\n            marker_line_width=0.5,\n            name='Transit Count'\n        ),\n        row=1, col=1\n    )\n    \n    # 2. Top N 혼잡 Edge\n    top_edges = edge_stats_sorted.head(top_n)\n    edge_labels = top_edges['edge_id_fmt'].to_list()\n    congestion_scores = top_edges['congestion_score'].to_list()\n    \n    fig.add_trace(\n        go.Bar(\n            y=edge_labels[::-1],  # 역순으로 표시 (높은 것이 위로)\n            x=congestion_scores[::-1],\n            orientation='h',\n            marker_color='coral',\n            text=[f'{s:.1f}' for s in congestion_scores[::-1]],\n            textposition='outside',\n            name='Congestion Score'\n        ),\n        row=1, col=2\n    )\n    \n    # Layout 설정\n    fig.update_xaxes(title_text='Transit Count', row=1, col=1)\n    fig.update_yaxes(title_text='Number of Edges', row=1, col=1)\n    \n    fig.update_xaxes(title_text='Congestion Score', row=1, col=2)\n    fig.update_yaxes(title_text='Edge ID', row=1, col=2)\n    \n    fig.update_layout(\n        height=600,\n        showlegend=False,\n        title_text='Edge Congestion Analysis (Edge Type별 기대 속도 반영)'\n    )\n    \n    fig.show()\n    \n    return edge_stats_sorted\n\nedge_congestion = analyze_edge_congestion(df)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vehicle Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\ndef analyze_vehicle_utilization(df):\n    \"\"\"Vehicle별 활용률 분석\"\"\"\n    \n    veh_stats = df.group_by('veh_id').agg([\n        pl.len().alias('transit_count'),\n        pl.col('timestamp').min().alias('first_time'),\n        pl.col('timestamp').max().alias('last_time'),\n        pl.col('transit_time').sum().alias('total_transit_time'),\n        pl.col('transit_time').mean().alias('avg_transit_time'),\n        pl.col('edge_length').sum().alias('total_distance'),\n        pl.col('fab_id').first().alias('fab_id'),\n    ])\n    \n    veh_stats = veh_stats.with_columns([\n        (pl.col('last_time') - pl.col('first_time')).alias('active_duration')\n    ]).with_columns([\n        (pl.col('total_transit_time') / pl.col('active_duration') * 100).clip(0, 100).alias('utilization')\n    ])\n    \n    print('\\nVehicle Utilization Summary:')\n    print(f'  Mean Utilization: {veh_stats[\"utilization\"].mean():.1f}%')\n    print(f'  Median Utilization: {veh_stats[\"utilization\"].median():.1f}%')\n    print(f'  Total Distance (all vehicles): {veh_stats[\"total_distance\"].sum():.1f}m')\n    \n    # 시각화\n    fig = make_subplots(\n        rows=2, cols=2,\n        subplot_titles=(\n            'Vehicle Utilization Distribution',\n            'Transits per Vehicle',\n            'Vehicle Utilization by Fab',\n            'Total Distance per Vehicle'\n        )\n    )\n    \n    # 1. 활용률 분포\n    utilizations = veh_stats['utilization'].to_list()\n    mean_util = veh_stats['utilization'].mean()\n    \n    fig.add_trace(\n        go.Histogram(\n            x=utilizations,\n            nbinsx=30,\n            marker_color='lightblue',\n            marker_line_color='black',\n            marker_line_width=0.5,\n        ),\n        row=1, col=1\n    )\n    \n    fig.add_vline(\n        x=mean_util,\n        line_dash='dash',\n        line_color='red',\n        row=1, col=1\n    )\n    \n    # 2. 통과 횟수 분포\n    transit_counts = veh_stats['transit_count'].to_list()\n    \n    fig.add_trace(\n        go.Histogram(\n            x=transit_counts,\n            nbinsx=30,\n            marker_color='lightgreen',\n            marker_line_color='black',\n            marker_line_width=0.5,\n        ),\n        row=1, col=2\n    )\n    \n    # 3. Fab별 활용률\n    if df['fab_id'].n_unique() > 1:\n        fab_util = veh_stats.group_by('fab_id').agg([\n            pl.col('utilization').mean().alias('mean_utilization')\n        ]).sort('fab_id')\n        \n        fig.add_trace(\n            go.Bar(\n                x=fab_util['fab_id'].to_list(),\n                y=fab_util['mean_utilization'].to_list(),\n                marker_color='lightcoral',\n                text=[f'{v:.1f}%' for v in fab_util['mean_utilization'].to_list()],\n                textposition='outside',\n            ),\n            row=2, col=1\n        )\n    else:\n        fig.add_annotation(\n            text='Single Fab',\n            xref='x3', yref='y3',\n            x=0.5, y=0.5,\n            showarrow=False,\n            row=2, col=1\n        )\n    \n    # 4. 총 이동거리 분포\n    total_distances = veh_stats['total_distance'].to_list()\n    \n    fig.add_trace(\n        go.Histogram(\n            x=total_distances,\n            nbinsx=30,\n            marker_color='lightyellow',\n            marker_line_color='black',\n            marker_line_width=0.5,\n        ),\n        row=2, col=2\n    )\n    \n    # Layout 설정\n    fig.update_xaxes(title_text='Utilization (%)', row=1, col=1)\n    fig.update_yaxes(title_text='Number of Vehicles', row=1, col=1)\n    \n    fig.update_xaxes(title_text='Transit Count', row=1, col=2)\n    fig.update_yaxes(title_text='Number of Vehicles', row=1, col=2)\n    \n    fig.update_xaxes(title_text='Fab ID', row=2, col=1)\n    fig.update_yaxes(title_text='Mean Utilization (%)', row=2, col=1)\n    \n    fig.update_xaxes(title_text='Total Distance (m)', row=2, col=2)\n    fig.update_yaxes(title_text='Number of Vehicles', row=2, col=2)\n    \n    fig.update_layout(\n        height=900,\n        showlegend=False,\n        title_text='Vehicle Utilization Analysis'\n    )\n    \n    fig.show()\n    \n    return veh_stats\n\nveh_utilization = analyze_vehicle_utilization(df)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Multiple Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_experiments(file_paths, names=None):\n",
    "    \"\"\"\n",
    "    여러 실험 결과 로드\n",
    "    \n",
    "    Args:\n",
    "        file_paths: 로그 파일 경로 리스트\n",
    "        names: 실험 이름 리스트 (없으면 파일명 사용)\n",
    "    \"\"\"\n",
    "    experiments = {}\n",
    "    \n",
    "    for i, path in enumerate(file_paths):\n",
    "        path = Path(path)\n",
    "        name = names[i] if names else path.stem\n",
    "        \n",
    "        df = parse_log_file(path)\n",
    "        experiments[name] = df\n",
    "        print(f'Loaded {name}: {len(df):,} records')\n",
    "    \n",
    "    return experiments\n",
    "\n",
    "def compare_experiments(experiments):\n",
    "    \"\"\"실험 결과 비교 (Plotly)\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for name, df in experiments.items():\n",
    "        duration = (df['timestamp'].max() - df['timestamp'].min()) / 1000\n",
    "        comparison_data.append({\n",
    "            'experiment': name,\n",
    "            'records': len(df),\n",
    "            'duration_sec': duration,\n",
    "            'throughput': len(df) / duration,\n",
    "            'transit_mean': df['transit_time'].mean(),\n",
    "            'transit_median': df['transit_time'].median(),\n",
    "            'speed_mean': df['speed'].mean(),\n",
    "            'unique_vehicles': df['veh_id'].n_unique(),\n",
    "            'unique_edges': df['edge_id'].n_unique(),\n",
    "        })\n",
    "    \n",
    "    comp_df = pl.DataFrame(comparison_data)\n",
    "    print('\\nExperiment Comparison:')\n",
    "    print(comp_df)\n",
    "    \n",
    "    # 시각화\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Throughput Comparison',\n",
    "            'Transit Time Comparison',\n",
    "            'Average Speed Comparison',\n",
    "            'Transit Time Distribution'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    exp_names = list(experiments.keys())\n",
    "    \n",
    "    # 1. Throughput 비교\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=comp_df['experiment'].to_list(),\n",
    "            y=comp_df['throughput'].to_list(),\n",
    "            marker_color='lightblue',\n",
    "            text=[f'{v:.1f}' for v in comp_df['throughput'].to_list()],\n",
    "            textposition='outside',\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Transit Time 비교 (Mean vs Median)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=comp_df['experiment'].to_list(),\n",
    "            y=comp_df['transit_mean'].to_list(),\n",
    "            name='Mean',\n",
    "            marker_color='lightcoral',\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=comp_df['experiment'].to_list(),\n",
    "            y=comp_df['transit_median'].to_list(),\n",
    "            name='Median',\n",
    "            marker_color='lightgreen',\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Speed 비교\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=comp_df['experiment'].to_list(),\n",
    "            y=comp_df['speed_mean'].to_list(),\n",
    "            marker_color='lightyellow',\n",
    "            text=[f'{v:.2f}' for v in comp_df['speed_mean'].to_list()],\n",
    "            textposition='outside',\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Transit Time 분포 비교 (Box plot)\n",
    "    for name in exp_names:\n",
    "        transit_data = experiments[name]['transit_time'].to_list()\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=transit_data,\n",
    "                name=name,\n",
    "                boxmean='sd'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # Layout 설정\n",
    "    fig.update_xaxes(title_text='Experiment', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Throughput (transits/sec)', row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Experiment', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Transit Time (ms)', row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Experiment', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Speed (m/s)', row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text='Experiment', row=2, col=2)\n",
    "    fig.update_yaxes(title_text='Transit Time (ms)', row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        showlegend=True,\n",
    "        title_text='Experiment Comparison'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return comp_df\n",
    "\n",
    "# 예시: 여러 실험 비교\n",
    "# experiments = load_multiple_experiments([\n",
    "#     LOG_DIR / 'experiment_baseline.bin',\n",
    "#     LOG_DIR / 'experiment_new_routing.bin',\n",
    "#     LOG_DIR / 'experiment_optimized.bin',\n",
    "# ], names=['Baseline', 'New Routing', 'Optimized'])\n",
    "# compare_experiments(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 내보내기\n",
    "OUTPUT_DIR = Path('/content/drive/MyDrive/vps_logs/output')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 전체 데이터\n",
    "# df.write_csv(OUTPUT_DIR / 'full_data.csv')\n",
    "\n",
    "# 요약 통계\n",
    "# fab_stats.write_csv(OUTPUT_DIR / 'fab_stats.csv')\n",
    "# edge_congestion.write_csv(OUTPUT_DIR / 'edge_congestion.csv')\n",
    "# veh_utilization.write_csv(OUTPUT_DIR / 'vehicle_utilization.csv')\n",
    "\n",
    "print('Export examples (uncomment to use):')\n",
    "print('  df.write_csv(OUTPUT_DIR / \"full_data.csv\")')\n",
    "print('  fab_stats.write_csv(OUTPUT_DIR / \"fab_stats.csv\")')\n",
    "print('  edge_congestion.write_csv(OUTPUT_DIR / \"edge_congestion.csv\")')\n",
    "print('  veh_utilization.write_csv(OUTPUT_DIR / \"vehicle_utilization.csv\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Analysis\n",
    "\n",
    "자유롭게 분석 코드를 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 커스텀 분석 코드 작성\n",
    "# 예시:\n",
    "#\n",
    "# # 특정 Fab만 필터링\n",
    "# fab0_df = df.filter(pl.col('fab_id') == 0)\n",
    "#\n",
    "# # 특정 시간대만 필터링\n",
    "# start_time = 10000  # 10초 이후\n",
    "# end_time = 60000    # 60초까지\n",
    "# time_filtered = df.filter(\n",
    "#     (pl.col('timestamp') >= start_time) & (pl.col('timestamp') <= end_time)\n",
    "# )\n",
    "#\n",
    "# # Edge Type별 평균 속도\n",
    "# df.group_by('edge_type_name').agg([\n",
    "#     pl.col('speed').mean().alias('avg_speed')\n",
    "# ])\n",
    "#\n",
    "# # 혼잡한 Edge들만 필터링해서 자세히 보기\n",
    "# congested_edges = edge_congestion.head(10)['edge_id'].to_list()\n",
    "# congested_df = df.filter(pl.col('edge_id').is_in(congested_edges))\n",
    "#\n",
    "# # Lazy API로 대용량 데이터 처리 (메모리 효율적)\n",
    "# lazy_df = pl.scan_csv('large_file.csv')  # 파일을 바로 읽지 않고 lazy하게\n",
    "# result = lazy_df.filter(pl.col('fab_id') == 0).group_by('edge_id').agg([\n",
    "#     pl.col('transit_time').mean()\n",
    "# ]).collect()  # collect()를 호출할 때 실제 계산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Polars 대용량 데이터 처리 팁\n",
    "\n",
    "### 구글 코랩에서 대용량 로그 분석하기\n",
    "\n",
    "Polars는 pandas보다 **훨씬 빠르고 메모리 효율적**입니다:\n",
    "\n",
    "- **속도**: Rust 기반으로 멀티코어를 완전히 활용\n",
    "- **메모리**: pandas보다 2-5배 적은 메모리 사용\n",
    "- **Lazy evaluation**: 필요한 연산만 수행\n",
    "- **Streaming**: 메모리보다 큰 데이터도 처리 가능\n",
    "\n",
    "### 구글 코랩 무료 vs Pro\n",
    "\n",
    "- **무료**: RAM ~12GB, 데이터 크기 제한적\n",
    "- **Pro ($10/월)**: RAM ~25GB, GPU 사용 가능\n",
    "- **Pro+**: RAM ~50GB, 대용량 데이터 처리 가능\n",
    "\n",
    "### 권장사항\n",
    "\n",
    "- **소규모 (~100MB)**: 코랩 무료 충분\n",
    "- **중규모 (100MB-1GB)**: Polars + 코랩 무료로 가능\n",
    "- **대규모 (1GB+)**: Polars streaming + 코랩 Pro 권장\n",
    "- **초대규모 (10GB+)**: 로컬 환경 권장 (RAM 32GB+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 사용량 체크\n",
    "import psutil\n",
    "\n",
    "def check_memory_usage():\n",
    "    \"\"\"현재 메모리 사용량 확인\"\"\"\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    mem_mb = mem_info.rss / 1024 / 1024\n",
    "    \n",
    "    # 시스템 전체 메모리\n",
    "    vm = psutil.virtual_memory()\n",
    "    total_mb = vm.total / 1024 / 1024\n",
    "    available_mb = vm.available / 1024 / 1024\n",
    "    used_percent = vm.percent\n",
    "    \n",
    "    print(f'현재 프로세스 메모리 사용량: {mem_mb:.1f} MB')\n",
    "    print(f'시스템 총 메모리: {total_mb:.1f} MB')\n",
    "    print(f'사용 가능 메모리: {available_mb:.1f} MB')\n",
    "    print(f'메모리 사용률: {used_percent:.1f}%')\n",
    "    \n",
    "    if used_percent > 80:\n",
    "        print('⚠️  메모리 사용률이 높습니다! 다음을 고려하세요:')\n",
    "        print('  1. 불필요한 변수 삭제: del large_df')\n",
    "        print('  2. 필요한 컬럼만 선택: df.select([...필요한 컬럼...])')\n",
    "        print('  3. 데이터 필터링: df.filter(...)')\n",
    "        print('  4. 코랩 Pro로 업그레이드')\n",
    "    \n",
    "    return {\n",
    "        'process_mb': mem_mb,\n",
    "        'total_mb': total_mb,\n",
    "        'available_mb': available_mb,\n",
    "        'used_percent': used_percent\n",
    "    }\n",
    "\n",
    "# DataFrame 크기 확인\n",
    "def check_dataframe_size(df, name='df'):\n",
    "    \"\"\"DataFrame의 메모리 사용량 확인\"\"\"\n",
    "    # Polars DataFrame의 메모리 사용량 추정\n",
    "    mem_bytes = df.estimated_size()\n",
    "    mem_mb = mem_bytes / 1024 / 1024\n",
    "    \n",
    "    print(f'{name} 크기: {len(df):,} rows × {len(df.columns)} cols')\n",
    "    print(f'{name} 메모리: {mem_mb:.1f} MB')\n",
    "    \n",
    "    return mem_mb\n",
    "\n",
    "print('=== 메모리 사용량 체크 ===\\n')\n",
    "mem_info = check_memory_usage()\n",
    "print('\\n=== DataFrame 크기 ===\\n')\n",
    "df_size = check_dataframe_size(df, 'df')\n",
    "\n",
    "# 최적화 팁\n",
    "print('\\n=== Polars 최적화 팁 ===\\n')\n",
    "print('1. 필요한 컬럼만 로드:')\n",
    "print('   df.select([\"edge_id\", \"transit_time\", \"speed\"])')\n",
    "print('\\n2. Lazy API 사용 (대용량 데이터):')\n",
    "print('   lazy_df = pl.scan_parquet(\"large_file.parquet\")')\n",
    "print('   result = lazy_df.filter(...).group_by(...).agg(...).collect()')\n",
    "print('\\n3. 메모리 절약을 위한 타입 변환:')\n",
    "print('   df.with_columns([pl.col(\"edge_id\").cast(pl.UInt16)])  # Int32 → UInt16')\n",
    "print('\\n4. 청크 단위로 처리:')\n",
    "print('   for chunk in pl.read_csv_batched(\"large.csv\", batch_size=10000):')\n",
    "print('       process(chunk)')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}